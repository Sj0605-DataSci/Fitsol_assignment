{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "from datetime import datetime\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import re\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WasteManagementScraper:\n",
    "    def __init__(self, username, password, output_dir=\"waste_management_data\"):\n",
    "        \"\"\"Initialize the Waste Management LinkedIn scraper\"\"\"\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.output_dir = output_dir\n",
    "        self.driver = None\n",
    "        self.wait_time_range = (50, 60)\n",
    "        \n",
    "        # Create output directory\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Download ChromeDriver and Chrome Headless Shell\n",
    "        self.download_chromedriver()\n",
    "        self.download_chrome_headless_shell()\n",
    "\n",
    "    def download_file(self, url, dest):\n",
    "        \"\"\"Download a file from a URL to a specified destination.\"\"\"\n",
    "        response = requests.get(url)\n",
    "        with open(dest, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "\n",
    "    def download_chromedriver(self):\n",
    "        \"\"\"Download ChromeDriver.\"\"\"\n",
    "        chromedriver_url = \"https://storage.googleapis.com/chrome-for-testing-public/131.0.6778.85/mac-x64/chromedriver-mac-x64.zip\"\n",
    "        dest = \"chromedriver.zip\"\n",
    "        self.download_file(chromedriver_url, dest)\n",
    "        \n",
    "        # Unzip the downloaded file\n",
    "        with zipfile.ZipFile(dest, 'r') as zip_ref:\n",
    "            zip_ref.extractall(\".\")\n",
    "        os.remove(dest)  # Remove the zip file after extraction\n",
    "        os.chmod(\"chromedriver\", 0o755)  # Make it executable\n",
    "\n",
    "    def download_chrome_headless_shell(self):\n",
    "        \"\"\"Download Chrome Headless Shell.\"\"\"\n",
    "        headless_shell_url = \"https://storage.googleapis.com/chrome-for-testing-public/131.0.6778.85/mac-x64/chrome-headless-shell-mac-x64.zip\"\n",
    "        dest = \"chrome-headless-shell.zip\"\n",
    "        self.download_file(headless_shell_url, dest)\n",
    "        \n",
    "        # Unzip the downloaded file\n",
    "        with zipfile.ZipFile(dest, 'r') as zip_ref:\n",
    "            zip_ref.extractall(\".\")\n",
    "        os.remove(dest)  # Remove the zip file after extraction\n",
    "        os.chmod(\"chrome-headless-shell\", 0o755)  # Make it executable\n",
    "\n",
    "    def setup_driver(self):\n",
    "        \"\"\"Configure and return ChromeDriver with appropriate settings for local setup.\"\"\"\n",
    "        chrome_options = webdriver.ChromeOptions()\n",
    "        \n",
    "        # Set headless mode\n",
    "        chrome_options.binary_location = os.path.abspath(\"chrome-headless-shell\")  # Use the headless shell\n",
    "        chrome_options.add_argument('--headless')  # Run in headless mode\n",
    "        chrome_options.add_argument('--disable-gpu')\n",
    "        chrome_options.add_argument('--disable-extensions')\n",
    "        chrome_options.add_argument('--ignore-certificate-errors')\n",
    "        chrome_options.add_argument('--ignore-ssl-errors')\n",
    "        chrome_options.add_argument(\"--enable-javascript\")\n",
    "        chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "        \n",
    "        # Update this path to the actual location of chromedriver\n",
    "        chromedriver_path = \"/Users/sammy/Desktop/Fitsol/Market_assignment/chromedriver-mac-x64/chromedriver\"\n",
    "        \n",
    "        if not os.path.exists(chromedriver_path):\n",
    "            raise FileNotFoundError(f\"ChromeDriver not found at {chromedriver_path}\")\n",
    "        \n",
    "        service = Service(chromedriver_path)\n",
    "        \n",
    "        # Initialize driver\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "        \n",
    "        # Set timeouts\n",
    "        driver.set_page_load_timeout(60)\n",
    "        driver.implicitly_wait(20)\n",
    "        \n",
    "        # Test the driver\n",
    "        driver.get('https://www.google.com')\n",
    "        print(\"Driver setup successful!\")\n",
    "        print(f\"Using Chrome version: {driver.capabilities['browserVersion']}\")\n",
    "        \n",
    "        return driver\n",
    "\n",
    "    def verify_setup(self):\n",
    "      \"\"\"Verify that the Chrome setup is working\"\"\"\n",
    "      try:\n",
    "          print(\"Verifying Chrome setup...\")\n",
    "          print(\"Chrome binary location:\", self.driver.capabilities['chrome']['chromedriverVersion'])\n",
    "          print(\"Current URL:\", self.driver.current_url)\n",
    "          return True\n",
    "      except Exception as e:\n",
    "          print(f\"Setup verification failed: {str(e)}\")\n",
    "          return False      \n",
    "\n",
    "    def login(self):\n",
    "        \"\"\"Log into LinkedIn with 2FA handling\"\"\"\n",
    "        try:\n",
    "            print(\"Initiating login process...\")\n",
    "            self.driver = self.setup_driver()\n",
    "            \n",
    "            # Test if driver is working\n",
    "            if not self.verify_setup():\n",
    "              print(\"Chrome setup verification failed!\")\n",
    "              return False\n",
    "        \n",
    "            print(\"Chrome setup verified. Proceeding with login...\")\n",
    "            \n",
    "            # Proceed with LinkedIn login\n",
    "            print(\"Navigating to LinkedIn...\")\n",
    "            self.driver.get('https://www.linkedin.com/login')\n",
    "            self.random_wait()\n",
    "            \n",
    "            # Enter username\n",
    "            username_field = WebDriverWait(self.driver, 20).until(\n",
    "                EC.presence_of_element_located((By.ID, \"username\"))\n",
    "            )\n",
    "            username_field.send_keys(self.username)\n",
    "            self.random_wait(2, 4)\n",
    "            \n",
    "            # Enter password\n",
    "            password_field = self.driver.find_element(By.ID, \"password\")\n",
    "            password_field.send_keys(self.password)\n",
    "            self.random_wait(2, 4)\n",
    "            \n",
    "            # Click sign in\n",
    "            sign_in_button = self.driver.find_element(By.CSS_SELECTOR, \"button[type='submit']\")\n",
    "            sign_in_button.click()\n",
    "            \n",
    "            # Handle 2FA\n",
    "            try:\n",
    "                print(\"Waiting for 2FA prompt...\")\n",
    "                pin_field = WebDriverWait(self.driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, \"input[name='pin']\"))\n",
    "                )\n",
    "                \n",
    "                verification_code = input(\"\\nPlease enter the 6-digit verification code sent to your email/phone: \")\n",
    "                pin_field.send_keys(verification_code)\n",
    "                self.random_wait(1, 2)\n",
    "                \n",
    "                verify_button = self.driver.find_element(By.CSS_SELECTOR, \"button[type='submit']\")\n",
    "                verify_button.click()\n",
    "                \n",
    "            except TimeoutException:\n",
    "                print(\"No 2FA prompt found - checking if login was successful...\")\n",
    "            \n",
    "            # Final check for successful login\n",
    "            try:\n",
    "                WebDriverWait(self.driver, 30).until(\n",
    "                    EC.presence_of_element_located((By.ID, \"global-nav\"))\n",
    "                )\n",
    "                print(\"Successfully logged in!\")\n",
    "                self.random_wait()\n",
    "                return True\n",
    "                \n",
    "            except TimeoutException:\n",
    "                print(\"Login failed - could not verify successful login\")\n",
    "                # Save page source for debugging\n",
    "                with open('login_page.html', 'w', encoding='utf-8') as f:\n",
    "                    f.write(self.driver.page_source)\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Login failed: {str(e)}\")\n",
    "            if self.driver:\n",
    "                print(\"Current URL:\", self.driver.current_url)\n",
    "                with open('error_page.html', 'w', encoding='utf-8') as f:\n",
    "                    f.write(self.driver.page_source)\n",
    "            return False\n",
    "\n",
    "    def random_wait(self, min_time=None, max_time=None):\n",
    "        \"\"\"Wait for a random amount of time\"\"\"\n",
    "        if min_time is None:\n",
    "            min_time = self.wait_time_range[0]\n",
    "        if max_time is None:\n",
    "            max_time = self.wait_time_range[1]\n",
    "        time.sleep(random.uniform(min_time, max_time))\n",
    "\n",
    "    def classify_waste_category(self, text):\n",
    "        \"\"\"Classify the waste management requirement into categories\"\"\"\n",
    "        text = text.lower()\n",
    "        categories = []\n",
    "        \n",
    "        for category, keywords in self.category_keywords.items():\n",
    "            if any(keyword.lower() in text for keyword in keywords):\n",
    "                categories.append(category)\n",
    "        \n",
    "        if not categories:\n",
    "            # Check for hazardous waste subcategories\n",
    "            hazardous_keywords = {\n",
    "                'chemical': 'G1',\n",
    "                'pesticide': 'G2',\n",
    "                'asbestos': 'G3',\n",
    "                'sludge': 'G4',\n",
    "                'contaminated soil': 'G5'\n",
    "            }\n",
    "            \n",
    "            for keyword, subcode in hazardous_keywords.items():\n",
    "                if keyword in text:\n",
    "                    categories.append(f\"G-{subcode}\")\n",
    "            \n",
    "            # Check for non-hazardous waste subcategories\n",
    "            non_hazardous_keywords = {\n",
    "                'food': 'H1',\n",
    "                'paper': 'H2',\n",
    "                'textile': 'H3',\n",
    "                'glass': 'H4',\n",
    "                'wood': 'H5',\n",
    "                'rubber': 'H6'\n",
    "            }\n",
    "            \n",
    "            for keyword, subcode in non_hazardous_keywords.items():\n",
    "                if keyword in text:\n",
    "                    categories.append(f\"H-{subcode}\")\n",
    "        \n",
    "        return categories if categories else ['Unclassified']\n",
    "\n",
    "    def search_posts(self, search_term):\n",
    "        \"\"\"Search for posts using a specific term\"\"\"\n",
    "        try:\n",
    "            # Navigate to LinkedIn search\n",
    "            search_url = f\"https://www.linkedin.com/search/results/content/?keywords={search_term}&origin=GLOBAL_SEARCH_HEADER\"\n",
    "            self.driver.get(search_url)\n",
    "            self.random_wait()\n",
    "            \n",
    "            # Scroll and collect posts\n",
    "            posts_data = []\n",
    "            last_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            \n",
    "            while len(posts_data) < 100:  # Limit to 100 posts per search term\n",
    "                # Scroll down\n",
    "                self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                self.random_wait(3, 5)\n",
    "                \n",
    "                # Get posts\n",
    "                posts = self.driver.find_elements(By.CSS_SELECTOR, \".feed-shared-update-v2\")\n",
    "                \n",
    "                for post in posts:\n",
    "                    try:\n",
    "                        post_data = self.extract_post_data(post)\n",
    "                        if post_data and self.is_relevant_post(post_data['content']):\n",
    "                            posts_data.append(post_data)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error extracting post data: {str(e)}\")\n",
    "                        continue\n",
    "                \n",
    "                # Check if scrolled to bottom\n",
    "                new_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "            \n",
    "            return posts_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error searching posts: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    def extract_post_data(self, post_element):\n",
    "        \"\"\"Extract required data from a post\"\"\"\n",
    "        try:\n",
    "            # Extract post content\n",
    "            content = post_element.find_element(By.CSS_SELECTOR, \".feed-shared-update-v2__description\").text\n",
    "            \n",
    "            # Extract poster information\n",
    "            poster_info = post_element.find_element(By.CSS_SELECTOR, \".feed-shared-actor__title\")\n",
    "            poster_name = poster_info.text\n",
    "            \n",
    "            # Try to get designation and company\n",
    "            try:\n",
    "                designation_company = post_element.find_element(By.CSS_SELECTOR, \".feed-shared-actor__description\").text\n",
    "                designation, company = self.parse_designation_company(designation_company)\n",
    "            except:\n",
    "                designation, company = \"\", \"\"\n",
    "            \n",
    "            # Get post date\n",
    "            post_date = post_element.find_element(By.CSS_SELECTOR, \"time\").get_attribute(\"datetime\")\n",
    "            \n",
    "            # Classify waste category\n",
    "            categories = self.classify_waste_category(content)\n",
    "            \n",
    "            return {\n",
    "                'content': content,\n",
    "                'poster_name': poster_name,\n",
    "                'designation': designation,\n",
    "                'company': company,\n",
    "                'post_date': post_date,\n",
    "                'categories': categories\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting post data: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def parse_designation_company(self, text):\n",
    "        \"\"\"Parse designation and company from LinkedIn description\"\"\"\n",
    "        parts = text.split(' at ')\n",
    "        if len(parts) > 1:\n",
    "            return parts[0].strip(), parts[1].strip()\n",
    "        return text.strip(), \"\"\n",
    "\n",
    "    def is_relevant_post(self, content):\n",
    "        \"\"\"Check if the post is relevant to waste management requirements\"\"\"\n",
    "        relevant_keywords = [\n",
    "            'requirement', 'needed', 'looking for', 'seeking',\n",
    "            'waste', 'disposal', 'recycling', 'management'\n",
    "        ]\n",
    "        content_lower = content.lower()\n",
    "        return any(keyword in content_lower for keyword in relevant_keywords)\n",
    "\n",
    "    def save_data(self, data, filename=None):\n",
    "        \"\"\"Save scraped data to CSV and JSON\"\"\"\n",
    "        if filename is None:\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            filename = f'waste_management_data_{timestamp}'\n",
    "        \n",
    "        # Save as JSON\n",
    "        json_path = os.path.join(self.output_dir, f'{filename}.json')\n",
    "        with open(json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        # Save as CSV\n",
    "        df = pd.DataFrame(data)\n",
    "        csv_path = os.path.join(self.output_dir, f'{filename}.csv')\n",
    "        df.to_csv(csv_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        print(f\"Data saved to {json_path} and {csv_path}\")\n",
    "\n",
    "    def scrape_waste_management_requirements(self):\n",
    "        \"\"\"Main function to scrape waste management requirements\"\"\"\n",
    "        try:\n",
    "            if not self.login():\n",
    "                return\n",
    "            \n",
    "            all_posts = []\n",
    "            \n",
    "            for search_term in self.search_terms:\n",
    "                print(f\"Searching for: {search_term}\")\n",
    "                posts = self.search_posts(search_term)\n",
    "                all_posts.extend(posts)\n",
    "                self.random_wait()\n",
    "            \n",
    "            # Remove duplicates based on content\n",
    "            unique_posts = {post['content']: post for post in all_posts}.values()\n",
    "            \n",
    "            # Save data\n",
    "            self.save_data(list(unique_posts))\n",
    "            \n",
    "            return list(unique_posts)\n",
    "            \n",
    "        finally:\n",
    "            if self.driver:\n",
    "                self.driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution failed: [Errno 2] No such file or directory: 'chromedriver'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Get credentials securely\n",
    "        username = \"21f3001088@ds.study.iitm.ac.in\"\n",
    "        password = \"Ritesh@200212\"\n",
    "        \n",
    "        # Initialize and run scraper\n",
    "        scraper = WasteManagementScraper(username, password)\n",
    "        data = scraper.scrape_waste_management_requirements()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Execution failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21f3001088@ds.study.iitm.ac.in\n",
    "# Ritesh@200212"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
